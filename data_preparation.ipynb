{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticating with Kaggle using kaggle.json\n",
    "\n",
    "Navigate to https://www.kaggle.com. Then go to the [Account tab of your user profile](https://www.kaggle.com/me/account) and select Create API Token. This will trigger the download of kaggle.json, a file containing your API credentials.\n",
    "\n",
    "Then run the cell below to upload kaggle.json to your Colab runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "!ls\n",
    "if not Path('training_v2.csv').exists():\n",
    "  from google.colab import files\n",
    "\n",
    "  uploaded = files.upload()\n",
    "\n",
    "  for fn in uploaded.keys():\n",
    "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "        name=fn, length=len(uploaded[fn])))\n",
    "    \n",
    "  # Then move kaggle.json into the folder where the API expects to find it.\n",
    "  !mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
    "  !kaggle competitions download -c widsdatathon2020\n",
    "  !unzip training_v2.csv.zip\n",
    "  !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check whether the data was retrieved properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('training_v2.csv').set_index('patient_id').drop(columns = ['encounter_id','apache_4a_hospital_death_prob','apache_4a_icu_death_prob'])\n",
    "train_df.index.name = 'Patient'\n",
    "train_df.sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into different datasets for different hospitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_ids = train_df['hospital_id'].unique()\n",
    "n_hospitals = len(hospital_ids)\n",
    "\n",
    "if not Path('client_datasets').exists():\n",
    "  !mkdir client_datasets\n",
    "  %cd client_datasets\n",
    "  print(f\"We'll create {n_hospitals} datasets\")\n",
    "  for i,hospital_id in enumerate(hospital_ids):\n",
    "    train_df[train_df['hospital_id'] == hospital_id].to_csv(f\"icu_raw_{i}.csv\")\n",
    "  !ls\n",
    "  %cd .."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
